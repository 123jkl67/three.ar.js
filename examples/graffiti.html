<!--
/*
 * Copyright 2017 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<!DOCTYPE html>
<html lang="en">
<head>
  <title>three.ar.js - Graffiti</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, user-scalable=no,
  minimum-scale=1.0, maximum-scale=1.0">
  <style>
    body {
      font-family: monospace;
      margin: 0;
      overflow: hidden;
      position: fixed;
      width: 100%;
      height: 100vh;
      -webkit-user-select: none;
      user-select: none;
    }
    #info {
      position: absolute;
      left: 50%;
      bottom: 0;
      transform: translate(-50%, 0);
      margin: 1em;
      z-index: 10;
      display: block;
      width: 100%;
      line-height: 2em;
      text-align: center;
    }
    #info a, #info .title {
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }
    #info a {
      color: rgba(255, 255, 255, 0.8);
      background-color: rgba(40, 40, 40, 0.6);
      font-weight: bold;
      text-decoration: none;
    }
    .title {
      color: rgba(255, 255, 255, 0.9);
      background-color: rgba(40, 40, 40, 0.4);
      margin-left: 0.2em;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>
<body>
<div id="info">
    <a href="https://github.com/google-ar/three.ar.js">three.ar.js</a><span class="title">Graffiti Example</span>
    <p><span class="title">Touch and hold to draw in 3D space</span></p>
</div>
<input style="z-index: 100; position: absolute; left: 10px; top: 10px; width:10%; height:10%" id="picker" type="color" value="#ff00ff">
<script src="../third_party/three.js/three.js"></script>
<script src="../third_party/three.js/VRControls.js"></script>
<script src="../dist/three.ar.js"></script>
<script id="fragmentShader" type="shader">
precision mediump float;
precision mediump int;

uniform vec3 color;

varying vec3 vPosition;
varying vec3 vNormal;
varying vec2 vUv;
varying vec3 vVelocity;

void main()	{
  vec2 uv = vUv;
  uv *= 2.0;
  uv -= 1.0;
  float value = 1.0 - abs( uv.y );
  value = smoothstep( 0.0, 0.05, value );
	gl_FragColor = vec4(color, value);
}
</script>
<script id="vertexShader" type="shader">
  uniform mat4 modelViewMatrix;
  uniform mat4 projectionMatrix;

  attribute vec3 position;
  attribute vec3 normal;
  attribute vec2 uv;
  attribute vec3 velocity;

  varying vec3 vPosition;
  varying vec3 vNormal;
  varying vec2 vUv;
  varying vec3 vVelocity;

  void main()
  {
      vPosition = position;
      vNormal = normal;
      vUv = uv;
      vVelocity = velocity;
      gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
  }

</script>
<script>

var vrDisplay;
var vrControls;
var arView;

var canvas;
var camera;
var scene;
var renderer;

var reticle;
var light;

// Drawing constants.
var MINIMIM_POINT_DISTANCE = 0.01;
var MINIMUM_STROKE_POINTS = 2;
var STROKE_DISTANCE = 0.2;
var STROKE_WIDTH_EASING = 0.05;
var STROKE_WIDTH_MODIFIER = 1.6;

// Setup drawing variables.
var drawing = false;
var stroke = [];
var strokes = [];
var strokeIndex = 0;
//var drawMaterial = new THREE.MeshLambertMaterial( { color: 0xff00ff, side: THREE.DoubleSide } );

var drawMaterial = new THREE.RawShaderMaterial(
    {
      vertexShader: document.getElementById( 'vertexShader' ).textContent,
      fragmentShader: document.getElementById( 'fragmentShader' ).textContent,
      side: THREE.DoubleSide,
      transparent: true,
      uniforms: {
        color: {
          value: new THREE.Color(0xff00ff)
        }
      }
    });

// Create a color picker for doing different colored strokes.
var colorPicker = document.getElementById('picker');
colorPicker.addEventListener('change', watchColorPicker, false);
function watchColorPicker(event) {
  drawMaterial = drawMaterial.clone();
  drawMaterial.uniforms.color.value = new THREE.Color(event.target.value);
  reticle.material = drawMaterial;
}

/**
 * Use the `getARDisplay()` utility to leverage the WebVR API
 * to see if there are any AR-capable WebVR VRDisplays. Returns
 * a valid display if found. Otherwise, display the unsupported
 * browser message.
 */
THREE.ARUtils.getARDisplay().then(function (display) {
  if (display) {
    vrDisplay = display;
    init();
  } else {
    THREE.ARUtils.displayUnsupportedMessage();
  }
});

function init() {
  // Turn on the debugging panel
  //var arDebug = new THREE.ARDebug(vrDisplay);
  //document.body.appendChild(arDebug.getElement());

  // Setup the three.js rendering environment
  renderer = new THREE.WebGLRenderer({ alpha: true });
  renderer.setPixelRatio(window.devicePixelRatio);
  renderer.setSize(window.innerWidth, window.innerHeight);
  renderer.autoClear = false;
  canvas = renderer.domElement;
  document.body.appendChild(canvas);
  scene = new THREE.Scene();

  // Creating the ARView, which is the object that handles
  // the rendering of the camera stream behind the three.js
  // scene
  arView = new THREE.ARView(vrDisplay, renderer);

  // The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera,
  // except when using an AR-capable browser, the camera uses
  // the projection matrix provided from the device, so that the
  // perspective camera's depth planes and field of view matches
  // the physical camera on the device.
  camera = new THREE.ARPerspectiveCamera(vrDisplay, 60, window.innerWidth / window.innerHeight, 0.01, 100);

  // VRControls is a utility from three.js that applies the device's
  // orientation/position to the perspective camera, keeping our
  // real world and virtual world in sync.
  vrControls = new THREE.VRControls(camera);

  // Bind our event handlers
  window.addEventListener('resize', onWindowResize, false);

  // Create a drawing reticle, which will be positioned in front of the device.
  var reticleGeometry = new THREE.SphereGeometry(0.01, 32, 32);
  reticle = new THREE.Mesh(reticleGeometry, drawMaterial);
  scene.add(reticle);

  // Create a light for the scene. We will position the light on the camera
  // and have it target the reticle, so the device acts like a flashlight into
  // the 3D scene.
  light = new THREE.DirectionalLight( 0xffffff );
  light.position.set( 0, 0, 1 );
  light.target = reticle;
  scene.add(light);
  
  // Start drawing when the user touches the screen.
  renderer.domElement.addEventListener('touchstart', function(event) {
    drawing = true;
  });

  // Stop the current draw stroke when the user finishes the touch.
  renderer.domElement.addEventListener('touchend', function(event) {
    drawing = false;
    stroke.length = 0;
    strokeIndex += 1;
  });

  update();
}

// Get a point in front of the device to use as the drawing location.
// Pass in a THREE.Vector3 to be populated with data to avoid creating garbage.
// This strange function structure is a way of avoiding creating garbage while
// generating the rotated forward vector.
var getDrawPoint = (function() {
  // Setup a basic forward vector (scaled down so it's not so far away).
  var forward = new THREE.Vector3(0, 0, -1).multiplyScalar(STROKE_DISTANCE);

  // Create a scratch vector for generating the rotated forward vector.
  var rotatedForward = new THREE.Vector3();
  return function(out) {
    // Start with the camera position, which is equivalent to device pose.
    out.copy(camera.position);

    // Rotate the forward vector by the pose orientation.
    rotatedForward.copy(forward);
    rotatedForward.applyQuaternion(camera.quaternion);
    out.add(rotatedForward);
  }
})();

var strokeWidth = 0;
var previousPosition = new THREE.Vector3();
var velocity = new THREE.Vector3();
function processDraw() {
  var position = new THREE.Vector3();
  getDrawPoint(position);

  // Don't use positions if they aren't far enough away from the previous point.
  if(stroke.length > MINIMUM_STROKE_POINTS && position.distanceTo(stroke[stroke.length - 1].position) < MINIMIM_POINT_DISTANCE) {
    return;
  }

  var normal = new THREE.Vector3(0, 0, 1);
  normal.applyQuaternion(camera.quaternion);
  //normal.subVectors(camera.position, position);
  normal.normalize();

  // Add the draw point to the current stroke.
  stroke.push(
      {
        position: position,
        normal: normal,
        velocity: new THREE.Vector3(velocity.x, velocity.y, velocity.z),
        width: strokeWidth
      });

  // Don't start drawing until there are enough points.
  if (stroke.length < MINIMUM_STROKE_POINTS) {
    return;
  }

  // Remove the old stroke from the scene so we can regenerate the stroke.
  if (strokes[strokeIndex]) {
    scene.remove(strokes[strokeIndex]);
  }

  /*
  // Generate a stroke from the current list of draw points.
  var spline = new THREE.CatmullRomCurve3(stroke);
  var geometry = new THREE.TubeBufferGeometry( spline, 100, 0.01, 3, false );
  */

  var positions = new Float32Array(stroke.length * 2 * 3);
  var normals = new Float32Array(stroke.length * 2 * 3);
  var uvs = new Float32Array(stroke.length * 2 * 2);
  var velocities = new Float32Array(stroke.length * 2 * 3);
  var v = new THREE.Vector3();
  var p1 = new THREE.Vector3();
  var p2 = new THREE.Vector3();
  for (var i = 0; i < stroke.length; i++) {
    var entry = stroke[i];
    v.crossVectors(entry.normal, entry.velocity);
    v.normalize();
    v.multiplyScalar(entry.width);
    p1.addVectors(entry.position, v);
    p2.subVectors(entry.position, v);
    var index = i * 2 * 3;
    positions[index] = p1.x;
    positions[index + 1] = p1.y;
    positions[index + 2] = p1.z;
    positions[index + 3] = p2.x;
    positions[index + 4] = p2.y;
    positions[index + 5] = p2.z;

    index = i * 2 * 3;
    normals[index] = entry.normal.x;
    normals[index + 1] = entry.normal.y;
    normals[index + 2] = entry.normal.z;
    normals[index + 3] = entry.normal.x;
    normals[index + 4] = entry.normal.y;
    normals[index + 5] = entry.normal.z;

    index = i * 2 * 3;
    velocities[index] = entry.velocity.x;
    velocities[index + 1] = entry.velocity.y;
    velocities[index + 2] = entry.velocity.z;
    velocities[index + 3] = entry.velocity.x;
    velocities[index + 4] = entry.velocity.y;
    velocities[index + 5] = entry.velocity.z;

    index = i * 2 * 2;
    uvs[index] = i / (stroke.length - 1);
    uvs[index + 1] = 0;
    uvs[index + 2] = i / (stroke.length - 1);
    uvs[index + 3] = 1;
  }

  var geometry = new THREE.BufferGeometry();
  function disposeArray() { this.array = null; }
  geometry.addAttribute('position', new THREE.BufferAttribute(positions, 3).onUpload(disposeArray));
  geometry.addAttribute('normal', new THREE.BufferAttribute(normals, 3).onUpload(disposeArray));
  geometry.addAttribute('uv', new THREE.BufferAttribute(uvs, 2).onUpload(disposeArray));
  geometry.addAttribute('velocity', new THREE.BufferAttribute(velocities, 3).onUpload(disposeArray));
  geometry.computeBoundingSphere();

  strokes[strokeIndex] = new THREE.Mesh(geometry, drawMaterial);
  strokes[strokeIndex].drawMode = THREE.TriangleStripDrawMode;
  scene.add(strokes[strokeIndex]);
}

/**
 * The render loop, called once per frame. Handles updating
 * our scene and rendering.
 */
function update() {
  // Render the device's camera stream on screen first of all.
  // It allows to get the right pose synchronized with the right frame.
  arView.render();

  // Update our camera projection matrix in the event that
  // the near or far planes have updated
  camera.updateProjectionMatrix();

  // Update our perspective camera's positioning
  vrControls.update();

  // Update the light pose to match the current device pose (the light acts
  // like a flashlight on the strokes).
  light.position.copy(camera.position);
  light.quaternion.copy(camera.quaternion);

  previousPosition.copy(reticle.position);
  // Update the reticle based on the current draw point.
  getDrawPoint(reticle.position);

  velocity.subVectors(reticle.position, previousPosition);
  strokeWidth = THREE.Math.lerp(strokeWidth, velocity.length() * STROKE_WIDTH_MODIFIER, STROKE_WIDTH_EASING);
  //reticle.scale.set(1 + (strokeWidth * 100), 1 + (strokeWidth * 100), 1 + (strokeWidth * 100));

  // Update the current graffiti stroke.
  if (drawing) {
    processDraw();
  }

  // Render our three.js virtual scene
  renderer.clearDepth();
  renderer.render(scene, camera);

  // Kick off the requestAnimationFrame to call this function
  // on the next frame
  requestAnimationFrame(update);
}

/**
 * On window resize, update the perspective camera's aspect ratio,
 * and call `updateProjectionMatrix` so that we can get the latest
 * projection matrix provided from the device
 */
function onWindowResize () {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
}

</script>
</body>
</html>
